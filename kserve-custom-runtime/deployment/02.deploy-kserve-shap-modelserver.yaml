apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  labels:
    controller-tools.k8s.io: "1.0"
  name: "kserve-custom-inference-service"
spec:
  predictor:
    containers:
    - image: pongsakornpongsutiyakorn/kserve-shap-model
      resources:
        requests:
          memory: "2048Mi"
          cpu: "250m"
        limits:
          memory: "2048Mi"
          cpu: "500m"
          env:
      env:
      - name: MODEL_NAME
        value: sample-crc
      - name: MLFLOW_URL
        valueFrom:
          secretKeyRef:
            name: mlflow-secret
            key: MLFLOW_URL
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: mlflow-secret
            key: AWS_ACCESS_KEY_ID
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: mlflow-secret
            key: AWS_SECRET_ACCESS_KEY
      - name: AWS_DEFAULT_REGION
        valueFrom:
          secretKeyRef:
            name: mlflow-secret
            key: AWS_DEFAULT_REGION